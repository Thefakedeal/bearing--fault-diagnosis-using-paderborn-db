{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/paderborn_local\n",
        "!unzip -q \"/content/drive/MyDrive/Padeborn_Dataset/padeborn.zip\" -d /content/paderborn_local"
      ],
      "metadata": {
        "id": "tmsP613C5RR3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/paderborn_local\""
      ],
      "metadata": {
        "id": "3R-9nWk7Mqw5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import scipy.stats\n",
        "import pandas as pd\n",
        "from scipy.fft import fft\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def extract_features(signal, segment_size=1024):\n",
        "    num_segments = len(signal) // segment_size\n",
        "    features = []\n",
        "    for i in range(num_segments):\n",
        "        seg = signal[i * segment_size : (i + 1) * segment_size]\n",
        "        f_vals = np.abs(fft(seg)[:segment_size // 2])\n",
        "\n",
        "        t_kurt = scipy.stats.kurtosis(seg)\n",
        "        f_p2p = np.ptp(f_vals)\n",
        "        f_skew = scipy.stats.skew(f_vals)\n",
        "        t_p2p = np.ptp(seg)\n",
        "        t_std = np.std(seg)\n",
        "        f_rms = np.sqrt(np.mean(f_vals**2))\n",
        "        f_crest = np.max(f_vals) / (f_rms + 1e-9)\n",
        "        f_kurt = scipy.stats.kurtosis(f_vals)\n",
        "\n",
        "        features.append([t_kurt, f_p2p, f_skew, t_p2p, t_std, f_rms, f_crest, f_kurt])\n",
        "    return features\n",
        "\n",
        "def get_signal(file_path):\n",
        "    try:\n",
        "        mat = scipy.io.loadmat(file_path)\n",
        "        key = [k for k in mat.keys() if not k.startswith('_')][0]\n",
        "        y_data = mat[key][0, 0]['Y']\n",
        "        for i in range(y_data.shape[1]):\n",
        "            if 'vibration_1' in y_data[0, i]['Name'][0]:\n",
        "                return y_data[0, i]['Data'].flatten()\n",
        "        return None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def build_dataset(base_path):\n",
        "    data_rows = []\n",
        "    for root, _, files in os.walk(base_path):\n",
        "        for f in files:\n",
        "            if f.endswith(\".mat\"):\n",
        "                label = -1\n",
        "                if \"K00\" in f: label = 0\n",
        "                elif \"KA\" in f: label = 1\n",
        "                elif \"KI\" in f: label = 2\n",
        "                elif \"KB\" in f: label = 3\n",
        "\n",
        "                if label == -1: continue\n",
        "\n",
        "                sig = get_signal(os.path.join(root, f))\n",
        "                if sig is not None:\n",
        "                    rpm = 900 if \"N09\" in f else 1500\n",
        "                    feats = extract_features(sig)\n",
        "                    for ft in feats:\n",
        "                        data_rows.append(ft + [rpm, label])\n",
        "\n",
        "    cols = [\n",
        "        'vibration_1_time_kurtosis', 'vibration_1_freq_peak_to_peak',\n",
        "        'vibration_1_freq_skewness', 'vibration_1_time_peak_to_peak',\n",
        "        'vibration_1_time_std_dev', 'vibration_1_freq_rms',\n",
        "        'vibration_1_freq_crest_factor', 'vibration_1_freq_kurtosis',\n",
        "        'rpm', 'label'\n",
        "    ]\n",
        "    return pd.DataFrame(data_rows, columns=cols)\n",
        "\n",
        "df = build_dataset(dataset_path)\n",
        "\n",
        "if not df.empty:\n",
        "    train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
        "    train_df.to_csv('/content/drive/MyDrive/Padeborn_Dataset/train_fft_quantum.csv', index=False)\n",
        "    test_df.to_csv('/content/drive/MyDrive/Padeborn_Dataset/test_fft_quantum.csv', index=False)\n",
        "    print(f\"Success! Train: {len(train_df)} | Test: {len(test_df)}\")\n",
        "else:\n",
        "    print(\"Check path or file naming.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swqNI8RfPUQE",
        "outputId": "5433a22a-bf98-4141-addd-69ba1f3ab53c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! Train: 513090 | Test: 128273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Padeborn_Dataset/train_fft_quantum.csv'\n",
        "test_path = '/content/drive/MyDrive/Padeborn_Dataset/test_fft_quantum.csv'\n",
        "\n",
        "if os.path.exists(train_path) and os.path.exists(test_path):\n",
        "    print(\"✅ Arquivos encontrados com sucesso!\")\n",
        "\n",
        "\n",
        "    df_train = pd.read_csv(train_path)\n",
        "    df_test = pd.read_csv(test_path)\n",
        "\n",
        "\n",
        "    print(f\"\\n--- Resumo do Dataset de Treino ---\")\n",
        "    print(f\"Total de amostras: {len(df_train)}\")\n",
        "    print(f\"Colunas: {df_train.columns.tolist()}\")\n",
        "\n",
        "\n",
        "    print(\"\\n--- Distribuição por Classe (Label) ---\")\n",
        "\n",
        "    print(df_train['label'].value_counts().sort_index())\n",
        "\n",
        "\n",
        "    print(\"\\n--- Distribuição por RPM ---\")\n",
        "    print(df_train['rpm'].value_counts())\n",
        "\n",
        "\n",
        "    print(\"\\n--- Primeiras 5 linhas ---\")\n",
        "    print(df_train.head())\n",
        "else:\n",
        "    print(\"❌ Erro: Os arquivos não foram encontrados. Verifique o caminho do salvamento.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz8QGasPeRER",
        "outputId": "be3af9db-1bdb-41f8-ce8d-b07fb53c27e8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Arquivos encontrados com sucesso!\n",
            "\n",
            "--- Resumo do Dataset de Treino ---\n",
            "Total de amostras: 513090\n",
            "Colunas: ['vibration_1_time_kurtosis', 'vibration_1_freq_peak_to_peak', 'vibration_1_freq_skewness', 'vibration_1_time_peak_to_peak', 'vibration_1_time_std_dev', 'vibration_1_freq_rms', 'vibration_1_freq_crest_factor', 'vibration_1_freq_kurtosis', 'rpm', 'label']\n",
            "\n",
            "--- Distribuição por Classe (Label) ---\n",
            "label\n",
            "0     96162\n",
            "1    192279\n",
            "2    176519\n",
            "3     48130\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Distribuição por RPM ---\n",
            "rpm\n",
            "1500    384954\n",
            "900     128136\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Primeiras 5 linhas ---\n",
            "   vibration_1_time_kurtosis  vibration_1_freq_peak_to_peak  \\\n",
            "0                   0.925965                      53.044153   \n",
            "1                   2.433260                      82.733287   \n",
            "2                   1.964131                      34.019643   \n",
            "3                   4.445548                      42.423530   \n",
            "4                   6.532173                      44.507963   \n",
            "\n",
            "   vibration_1_freq_skewness  vibration_1_time_peak_to_peak  \\\n",
            "0                   3.529068                       1.919556   \n",
            "1                   3.139069                       4.321289   \n",
            "2                   3.584681                       1.821899   \n",
            "3                   2.773794                       2.792358   \n",
            "4                   6.238045                       1.486206   \n",
            "\n",
            "   vibration_1_time_std_dev  vibration_1_freq_rms  \\\n",
            "0                  0.226580              7.495784   \n",
            "1                  0.480510             15.384120   \n",
            "2                  0.175906              5.715548   \n",
            "3                  0.236586              7.591778   \n",
            "4                  0.115129              4.177061   \n",
            "\n",
            "   vibration_1_freq_crest_factor  vibration_1_freq_kurtosis   rpm  label  \n",
            "0                       7.105229                  16.430485  1500      2  \n",
            "1                       5.379414                  10.994671  1500      3  \n",
            "2                       5.963667                  17.442534  1500      0  \n",
            "3                       5.604658                  11.999223  1500      1  \n",
            "4                      10.664558                  65.407682   900      2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Padeborn_Dataset/train_fft_quantum.csv')\n",
        "\n",
        "\n",
        "samples_per_class = 5000\n",
        "\n",
        "\n",
        "balanced_list = []\n",
        "\n",
        "for label in df['label'].unique():\n",
        "\n",
        "    subset = df[df['label'] == label]\n",
        "\n",
        "\n",
        "    n_samples = min(len(subset), samples_per_class)\n",
        "\n",
        "\n",
        "    balanced_subset = subset.sample(n=n_samples, random_state=42)\n",
        "    balanced_list.append(balanced_subset)\n",
        "\n",
        "\n",
        "df_balanced = pd.concat(balanced_list).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "df_balanced.to_csv('train_balanced_20k.csv', index=False)\n",
        "\n",
        "print(\"--- Novo Dataset de Treino Quântico ---\")\n",
        "print(f\"Total de amostras: {len(df_balanced)}\")\n",
        "print(\"\\nDistribuição por Classe:\")\n",
        "print(df_balanced['label'].value_counts().sort_index())\n",
        "print(\"\\nDistribuição por RPM:\")\n",
        "print(df_balanced['rpm'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFmAT_ihe7ZC",
        "outputId": "a9179f1b-dcc3-4811-9831-8bc97738eebb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Novo Dataset de Treino Quântico ---\n",
            "Total de amostras: 20000\n",
            "\n",
            "Distribuição por Classe:\n",
            "label\n",
            "0    5000\n",
            "1    5000\n",
            "2    5000\n",
            "3    5000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribuição por RPM:\n",
            "rpm\n",
            "1500    15013\n",
            "900      4987\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df_balanced = pd.read_csv('train_balanced_20k.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Padeborn_Dataset/test_fft_quantum.csv') # Usamos o teste original para validação real\n",
        "\n",
        "\n",
        "feature_cols = [\n",
        "    'vibration_1_time_kurtosis', 'vibration_1_freq_peak_to_peak',\n",
        "    'vibration_1_freq_skewness', 'vibration_1_time_peak_to_peak',\n",
        "    'vibration_1_time_std_dev', 'vibration_1_freq_rms',\n",
        "    'vibration_1_freq_crest_factor', 'vibration_1_freq_kurtosis'\n",
        "]\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(df_balanced[feature_cols])\n",
        "y_train = df_balanced['label'].values\n",
        "\n",
        "\n",
        "df_test_small = df_test.sample(n=2000, random_state=42)\n",
        "X_test_scaled = scaler.transform(df_test_small[feature_cols])\n",
        "y_test = df_test_small['label'].values\n",
        "\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Dados prontos!\")\n",
        "print(f\"X_train shape: {X_train_tensor.shape}\")\n",
        "print(f\"Gama de valores após scaler: {X_train_tensor.min().item():.2f} a {X_train_tensor.max().item():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX5zFR7GfOI8",
        "outputId": "f17db72c-aff9-4041-fcf3-a18ba7ffb831"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados prontos!\n",
            "X_train shape: torch.Size([20000, 8])\n",
            "Gama de valores após scaler: 0.00 a 3.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as pnp\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "n_qubits = 8\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_circuit(inputs, weights):\n",
        "\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "\n",
        "\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "\n",
        "class HybridQuantumModel(nn.Module):\n",
        "    def __init__(self, n_layers=3):\n",
        "        super().__init__()\n",
        "\n",
        "        weight_shapes = {\"weights\": (n_layers, n_qubits, 3)}\n",
        "\n",
        "\n",
        "        self.clayer_1 = qml.qnn.TorchLayer(quantum_circuit, weight_shapes)\n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(n_qubits, 4)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.clayer_1(x)\n",
        "        x = self.fc(x)\n",
        "        return self.softmax(x)\n",
        "\n",
        "\n",
        "model = HybridQuantumModel(n_layers=2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08NFTZBTfeN6",
        "outputId": "10da4be4-76f3-408f-ddc8-c9f434c4aa70"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HybridQuantumModel(\n",
            "  (clayer_1): <Quantum Torch Layer: func=quantum_circuit>\n",
            "  (fc): Linear(in_features=8, out_features=4, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_circuit_reupload(inputs, weights):\n",
        "\n",
        "    for i in range(weights.shape[0]):\n",
        "\n",
        "        qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "        qml.StronglyEntanglingLayers(weights[i:i+1], wires=range(n_qubits))\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "class QuantumTurboModel(nn.Module):\n",
        "    def __init__(self, n_layers=4):\n",
        "        super().__init__()\n",
        "\n",
        "        weight_shapes = {\"weights\": (n_layers, n_qubits, 3)}\n",
        "        self.quantum_layer = qml.qnn.TorchLayer(quantum_circuit_reupload, weight_shapes)\n",
        "\n",
        "        self.classical_head = nn.Sequential(\n",
        "            nn.Linear(8, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 4)\n",
        "        )\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        q_out = self.quantum_layer(x)\n",
        "        return self.softmax(self.classical_head(q_out))\n",
        "\n",
        "model_v3 = QuantumTurboModel(n_layers=4).to(device)\n",
        "optimizer = torch.optim.Adam(model_v3.parameters(), lr=0.01)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.5)"
      ],
      "metadata": {
        "id": "ViGceDwcjdvz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "\n",
        "df_train = pd.read_csv('train_balanced_20k.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Padeborn_Dataset/test_fft_quantum.csv').sample(2000, random_state=42)\n",
        "\n",
        "feature_cols = [\n",
        "    'vibration_1_time_kurtosis', 'vibration_1_freq_peak_to_peak',\n",
        "    'vibration_1_freq_skewness', 'vibration_1_time_peak_to_peak',\n",
        "    'vibration_1_time_std_dev', 'vibration_1_freq_rms',\n",
        "    'vibration_1_freq_crest_factor', 'vibration_1_freq_kurtosis'\n",
        "]\n",
        "\n",
        "X_train_raw = df_train[feature_cols].values\n",
        "X_test_raw = df_test[feature_cols].values\n",
        "\n",
        "\n",
        "std_scaler = StandardScaler()\n",
        "X_train_std = std_scaler.fit_transform(X_train_raw)\n",
        "X_test_std = std_scaler.transform(X_test_raw)\n",
        "\n",
        "\n",
        "mm_scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
        "X_train_final = mm_scaler.fit_transform(X_train_std)\n",
        "X_test_final = mm_scaler.transform(X_test_std)\n",
        "\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_final, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(df_train['label'].values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test_final, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(df_test['label'].values, dtype=torch.long)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"Dados normalizados com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W8MeTNAj9Yj",
        "outputId": "da9e3f3f-3982-4c5f-ca40-15c228baa8b5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados normalizados com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_v3 = train_model(\n",
        "    model=model_v3,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=test_loader,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    epochs=15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0QAjUDGjpHi",
        "outputId": "c389626a-0d70-455b-c84f-9d4576e743f4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/15: 100%|██████████| 625/625 [01:54<00:00,  5.47it/s, loss=0.9908, acc=56.69%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 Finalizada - Test Acc: 51.30% | Avg Loss: 0.9702\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15: 100%|██████████| 625/625 [01:49<00:00,  5.72it/s, loss=1.1265, acc=57.78%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 Finalizada - Test Acc: 53.65% | Avg Loss: 0.9413\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/15: 100%|██████████| 625/625 [01:26<00:00,  7.25it/s, loss=1.3294, acc=58.20%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 Finalizada - Test Acc: 54.85% | Avg Loss: 0.9350\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15: 100%|██████████| 625/625 [01:24<00:00,  7.39it/s, loss=1.0297, acc=58.92%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 Finalizada - Test Acc: 56.05% | Avg Loss: 0.9261\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/15: 100%|██████████| 625/625 [01:24<00:00,  7.40it/s, loss=0.9161, acc=59.22%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 Finalizada - Test Acc: 54.35% | Avg Loss: 0.9206\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15: 100%|██████████| 625/625 [01:24<00:00,  7.37it/s, loss=0.9261, acc=59.42%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 Finalizada - Test Acc: 56.60% | Avg Loss: 0.9139\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15: 100%|██████████| 625/625 [01:24<00:00,  7.36it/s, loss=0.8075, acc=59.05%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7 Finalizada - Test Acc: 55.90% | Avg Loss: 0.9160\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/15: 100%|██████████| 625/625 [01:24<00:00,  7.37it/s, loss=0.9278, acc=58.91%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 Finalizada - Test Acc: 54.40% | Avg Loss: 0.9196\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/15: 100%|██████████| 625/625 [01:24<00:00,  7.43it/s, loss=0.9330, acc=59.47%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9 Finalizada - Test Acc: 53.85% | Avg Loss: 0.9115\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15: 100%|██████████| 625/625 [01:24<00:00,  7.39it/s, loss=0.8614, acc=59.19%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 Finalizada - Test Acc: 55.75% | Avg Loss: 0.9095\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15: 100%|██████████| 625/625 [01:24<00:00,  7.39it/s, loss=0.8530, acc=59.30%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11 Finalizada - Test Acc: 55.20% | Avg Loss: 0.9095\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15: 100%|██████████| 625/625 [01:24<00:00,  7.38it/s, loss=0.8651, acc=59.72%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12 Finalizada - Test Acc: 49.00% | Avg Loss: 0.9095\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/15: 100%|██████████| 625/625 [01:25<00:00,  7.34it/s, loss=0.8881, acc=59.87%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13 Finalizada - Test Acc: 56.90% | Avg Loss: 0.9033\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/15: 100%|██████████| 625/625 [01:24<00:00,  7.42it/s, loss=0.9174, acc=60.15%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14 Finalizada - Test Acc: 54.90% | Avg Loss: 0.9002\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15: 100%|██████████| 625/625 [01:24<00:00,  7.42it/s, loss=0.8580, acc=60.12%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15 Finalizada - Test Acc: 55.65% | Avg Loss: 0.9041\n",
            "\n"
          ]
        }
      ]
    }
  ]
}